# -*- coding: utf-8 -*-
"""ModalShiftAnalyzer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HsSCYi8b1gXULPmTlxWBCC0nUEakb1jc
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    accuracy_score,
    classification_report,
    confusion_matrix,
    roc_auc_score,
    roc_curve
)
# Add these imports at the top if you haven't yet:
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from xgboost import XGBClassifier

class ModalShiftAnalyzer:
    """
    A class to handle training and evaluation of ML models for
    Modal Shift Prediction (Bus -> Metro).
    """

    def __init__(self, X_train, X_test, y_train, y_test):
        """
        Initialize with the training and testing data.
        """
        self.X_train = X_train
        self.X_test = X_test
        self.y_train = y_train
        self.y_test = y_test
        self.models = {} # Dictionary to store trained models
        self.results = {} # Dictionary to store performance metrics

    def train_random_forest(self, n_estimators=100, random_state=42):
        """
        Trains a Random Forest Classifier and prints evaluation metrics.
        """
        print("--- Training Random Forest Model ---")

        # 1. Initialize and Train
        # "Handles 43 features well" and "Non-linear relationships" [cite: 32]
        rf_model = RandomForestClassifier(n_estimators=n_estimators, random_state=random_state)
        rf_model.fit(self.X_train, self.y_train)

        # 2. Predictions
        y_pred = rf_model.predict(self.X_test)
        y_prob = rf_model.predict_proba(self.X_test)[:, 1] # Probability for ROC-AUC

        # 3. Store Model
        self.models['Random Forest'] = rf_model

        # 4. Evaluation Metrics
        acc = accuracy_score(self.y_test, y_pred)
        roc = roc_auc_score(self.y_test, y_prob)

        self.results['Random Forest'] = {
            'Accuracy': acc,
            'ROC_AUC': roc
        }

        # 5. Output Results (Matches Thesis Answer Format [cite: 12])
        print(f"Accuracy: {acc:.4f}")
        print(f"ROC-AUC Score: {roc:.4f}")
        print("\nClassification Report (Precision, Recall, F1):")
        print(classification_report(self.y_test, y_pred))

        # 6. Confusion Matrix Visualization
        cm = confusion_matrix(self.y_test, y_pred)
        plt.figure(figsize=(6, 4))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
        plt.title('Confusion Matrix: Random Forest')
        plt.ylabel('Actual Label')
        plt.xlabel('Predicted Label')
        plt.show()

        return rf_model
      # ... (Previous code: init and train_random_forest) ...

    def train_logistic_regression(self):
        """
        Trains Logistic Regression (Baseline Model).
        Why: 'Interpretable baseline model' per Guide.
        """
        print("\n--- Training Logistic Regression ---")
        lr_model = LogisticRegression(max_iter=1000, random_state=42)
        lr_model.fit(self.X_train, self.y_train)

        y_pred = lr_model.predict(self.X_test)
        y_prob = lr_model.predict_proba(self.X_test)[:, 1]

        acc = accuracy_score(self.y_test, y_pred)
        roc = roc_auc_score(self.y_test, y_prob)

        # Store for comparison
        self.models['Logistic Regression'] = lr_model
        self.results['Logistic Regression'] = {'Accuracy': acc, 'ROC_AUC': roc}

        print(f"Accuracy: {acc:.4f}")
        print(f"ROC-AUC Score: {roc:.4f}")
        print("\nClassification Report (Precision, Recall, F1):")
        print(classification_report(self.y_test, y_pred))
        return lr_model

    def train_svm(self):
        """
        Trains Support Vector Machine (SVM).
        Why: 'Effective for high-dimensional data' (43 features).
        """
        print("\n--- Training SVM ---")
        # probability=True is needed to calculate ROC-AUC later
        svm_model = SVC(probability=True, random_state=42)
        svm_model.fit(self.X_train, self.y_train)

        y_pred = svm_model.predict(self.X_test)
        y_prob = svm_model.predict_proba(self.X_test)[:, 1]

        acc = accuracy_score(self.y_test, y_pred)
        roc = roc_auc_score(self.y_test, y_prob)

        self.models['SVM'] = svm_model
        self.results['SVM'] = {'Accuracy': acc, 'ROC_AUC': roc}

        print(f"Accuracy: {acc:.4f}")
        print(f"ROC-AUC Score: {roc:.4f}")
        print("\nClassification Report (Precision, Recall, F1):")
        print(classification_report(self.y_test, y_pred))
        return svm_model

    def train_xgboost(self):
        """
        Trains XGBoost.
        Why: 'State-of-the-art gradient boosting' usually gives highest accuracy.
        """
        print("\n--- Training XGBoost ---")
        xgb_model = XGBClassifier(eval_metric='logloss', random_state=42)
        xgb_model.fit(self.X_train, self.y_train)

        y_pred = xgb_model.predict(self.X_test)
        y_prob = xgb_model.predict_proba(self.X_test)[:, 1]

        acc = accuracy_score(self.y_test, y_pred)
        roc = roc_auc_score(self.y_test, y_prob)

        self.models['XGBoost'] = xgb_model
        self.results['XGBoost'] = {'Accuracy': acc, 'ROC_AUC': roc}

        print(f"Accuracy: {acc:.4f}")
        print(f"ROC-AUC Score: {roc:.4f}")
        print("\nClassification Report (Precision, Recall, F1):")
        print(classification_report(self.y_test, y_pred))
        return xgb_model

    def compare_models(self):
        """
        Generates the final comparison table for the Thesis Results section.
        """
        print("\n--- Final Model Comparison ---")
        results_df = pd.DataFrame(self.results).T # Transpose to make models rows
        print(results_df)

        # Find the best model based on Accuracy
        best_model_name = results_df['Accuracy'].idxmax()
        print(f"\nBest Performing Model: {best_model_name}")
        return results_df, self.models[best_model_name]

# --- TEST BLOCK (Delete this when using real data) ---
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split

# 1. Generate Dummy Data (Simulating your 43 attributes)
X, y = make_classification(n_samples=250, n_features=43, random_state=42)
X_train_mock, X_test_mock, y_train_mock, y_test_mock = train_test_split(X, y, test_size=0.2, random_state=42)

# 2. Instantiate the Object
analyzer = ModalShiftAnalyzer(X_train_mock, X_test_mock, y_train_mock, y_test_mock)

# 3. Run Random Forest
rf_model = analyzer.train_random_forest()

lr_model = analyzer.train_logistic_regression()

svm_model = analyzer.train_svm()

xgboost_model = analyzer.train_xgboost()

comparison = analyzer.compare_models()

